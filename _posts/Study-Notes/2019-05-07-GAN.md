---
layout:     post
title:      "Basic of GAN"
subtitle:   "Generative Adversarial Network"
date:       2019-05-07 20:28:04
author:     "StephenNG"
header-img: "img/in-post/post-motion-deblur/bg.png"
tags:
    - ML
---

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

# 1. Intro

一个**Generator**，生成器，简称**G**，是一个neural network，也即一个function。

一个**Discriminator**，判别器，简称**D**，也是neural network，也即一个function。

给G一个较低维度的输入，G生成一个较高维度的输出（图片，句子，etc.）；

给D一个输入（图片，句子，etc.），输出一个分数，通常越高越好。

---

以图片生成为例：

1. 给G-v0随机低维向量，生成一堆图片，label为0，代表是机器生成；收集一堆人工生成图片，label为1；把这些数据给D-v0进行训练，得到的D-v1具有（初步）识别机器和人工图片的能力；

2. 固定D-v1，训练G-v0，使G-v0生成的图片在D的评分机制里面能得到尽量高的分，成为G-v1。这里G-v0会直接拿D-v1的function来进行梯度上升（因为要使分数尽量高，所以是上升）；如果把G比作学生，D比作老师，老师说人像要有两个圆圈（眼睛），那么学生就直接加上两个圆圈，然后老师说人像是彩色的，学生就给图片涂上彩色……

3. 固定G-v1，训练D-v1（再次利用收集的人工图像），使D能够区分G-v1和人工生成的图像，成为D-v2；

4. 循环进行步骤2~3……

---

* 为什么G不能自己学？

    实际上，Auto-Encoder（AE）的后半部分就相当于一个自己学的Generator。AE通过encoder把高维向量编码成低维向量，然后decoder再用这个低维向量生成高维向量，通过机器学习使生成的高维向量和原先的高维向量尽量相似。AE的decoder就相当于一个Generator。

    以图片作为高维向量举例。AE的问题是，训练集中取两个相似的图片，它们产生的低维向量进行插值得到的新的低维向量，通过decode产生的图片，理应是原先的两个相似图片的某种“平均”（比如，一个向左偏，一个向右偏，插值产生的就应该偏中间），但实际情况不是这样，可能会生成一些不make sense的图像，甚至是噪声。

    而针对此问题进行改进的Variational Auto-Encoder（VAE），在低维向量上加上了接近于标准高斯分布的噪声，这样就使得，不仅训练集里面的图片产生encode得到的低维向量decode出来的图片和原先很像，而且，与训练集里面的图片比较接近的图片经过encode-decode之后得到的图片也能和原先很像。

    但是VAE仍然有问题，它很难处理好，或说很难理解，高维向量的components之间的关系。以图片为例，最后一层layer代表着每个像素的值，如果相邻像素是在同一个component里面，那么他们应该相差不大；但是在神经网络里面，相邻像素之间并不能直接互相影响！

* 为什么D不能自己画？

    以图像为例，训练D的方法是给它很多人工图像，告诉它应该输出高分；但是全部都是positive examples，这样D就会把所有接收到的输入都当作高分，所以negative examples是很重要的。

    可以采用迭代的方法解决，由D自己生成negative examples。

    但是D需要通过枚举所有像素所有可能的颜色值，计算它们的分数，来生成图像，相当于解一个很大的argmax问题，非常艰难。而用G来产生negative examples就相当于用neural network来学习怎么解argmax，更intelligent，也简单很多。

---

